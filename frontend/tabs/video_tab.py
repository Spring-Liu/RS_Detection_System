import streamlit as st
import cv2
import numpy as np
import tempfile
import time
from utils.api_client import send_detect_request, decode_base64_image

from utils.config import VIDEO_FRAME_SKIP #

def process_frame(frame_bgr, model_name, category, conf):
    """
    å¤„ç†å•å¸§ï¼šè¾“å…¥ BGRï¼Œè¾“å‡º RGB
    """
    # 1. ç¼–ç å›¾ç‰‡ (OpenCV éœ€è¦ BGR è¾“å…¥)
    success, img_encoded = cv2.imencode('.jpg', frame_bgr)
    if not success:
        # å¤±è´¥è¿”å›åŸå›¾ (BGR -> RGB)
        return cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB), 0

    img_bytes = img_encoded.tobytes()

    # 2. å‘é€è¯·æ±‚

    success, result = send_detect_request(
        file_bytes=img_bytes,
        file_name="video_frame.jpg",
        file_type="image/jpeg",
        model_name=model_name,
        category=category,
        conf=conf,
        use_sahi=False,
        enhance_type="None"
    )

    if success:
        # 3. è§£ç ç»“æœ (PIL è§£ç å‡ºæ¥é»˜è®¤æ˜¯ RGB)
        res_img_pil = decode_base64_image(result['image_base64'])
        if res_img_pil:
            return np.array(res_img_pil), result['total_objects']

    # å…œåº•ï¼šè¿”å›åŸå›¾ (BGR -> RGB)
    return cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB), 0

def render_video_tab(model_dict: dict):
    st.markdown("### ğŸ“¹ è§†é¢‘ç›®æ ‡æ£€æµ‹")

    st.markdown("#### ğŸ•¹ï¸ æ£€æµ‹å‚æ•°é…ç½®")

    # ä½¿ç”¨ col1/col2/col3/col4 å°†å‚æ•°æ¨ªå‘æ’åˆ—
    col1, col2, col3, col4, col5 = st.columns([1.5, 2, 1.5, 1.5, 1])

    with col1:
        # âœ… å±€éƒ¨å˜é‡ category_choice
        category_choice = st.selectbox(
            "æ£€æµ‹åœºæ™¯", 
            ["aerial", "sar"],
            format_func=lambda x: "âœˆï¸ èˆªæ‹ (Aerial)" if x == "aerial" else "ğŸ“¡ é›·è¾¾ (SAR)",
            key="vid_scene_select"
        )

    # æå–å¯ç”¨æ¨¡å‹åˆ—è¡¨
    available_models = model_dict.get(category_choice, ["default"])

    with col2:

        model_choice = st.selectbox("é€‰æ‹©æ¨¡å‹æƒé‡", available_models, key="vid_model_select")

    with col3:

        conf_thres = st.slider("ç½®ä¿¡åº¦", 0.0, 1.0, 0.35, key="vid_conf_slider")

    with col4:

        use_sahi = st.checkbox("å¼€å¯ SAHI (é«˜å»¶è¿Ÿ)", value=False, key="vid_sahi_checkbox")

    with col5:

        fix_color = st.checkbox("ğŸ¨ é¢œè‰²å¼‚å¸¸ä¿®å¤", value=True, help="å¦‚æœçœ‹åˆ°é¢œè‰²åè½¬ï¼Œè¯·å‹¾é€‰æ­¤é¡¹")

    st.markdown("---")

    video_source = st.radio("é€‰æ‹©è§†é¢‘æº", ["æœ¬åœ°è§†é¢‘æ–‡ä»¶", "å®æ—¶æ‘„åƒå¤´ (Webcam)"], horizontal=True)

    st_frame = st.empty()
    kpi1, kpi2, kpi3 = st.columns(3)
    with kpi1: kpi_frame = st.empty()
    with kpi2: kpi_obj = st.empty()
    with kpi3: kpi_fps = st.empty()



    stop_button = st.button("ğŸ”´ åœæ­¢æ¨æµ", type="secondary")

    cap = None

    # åˆå§‹åŒ–è§†é¢‘æº
    if video_source == "æœ¬åœ°è§†é¢‘æ–‡ä»¶":
        video_file = st.file_uploader("ä¸Šä¼ è§†é¢‘æ–‡ä»¶", type=['mp4', 'avi'])
        if video_file:
            tfile = tempfile.NamedTemporaryFile(delete=False)
            tfile.write(video_file.read())
            cap = cv2.VideoCapture(tfile.name)
    elif video_source == "å®æ—¶æ‘„åƒå¤´ (Webcam)":
        if st.checkbox("å¯åŠ¨æ‘„åƒå¤´", key="start_webcam_checkbox"):
            cap = cv2.VideoCapture(0)

    # ä¸»å¾ªç¯
    if cap is not None and cap.isOpened():

        # ç¡®ä¿å¯åŠ¨æ‘„åƒå¤´å stop_button é»˜è®¤ä¸º Falseï¼Œé˜²æ­¢ç«‹å³åœæ­¢
        if 'stop_video_stream' not in st.session_state:
            st.session_state['stop_video_stream'] = False

        if stop_button:
            st.session_state['stop_video_stream'] = True

        frame_count = 0
        start_time = time.time()

        # âš ï¸ å¯åŠ¨å¾ªç¯ï¼Œç›´åˆ°ç”¨æˆ·ç‚¹å‡»åœæ­¢æˆ–è§†é¢‘ç»“æŸ
        while cap.isOpened() and not st.session_state['stop_video_stream']:

            ret, frame = cap.read() # è¿™é‡Œè¯»åˆ°çš„æ˜¯ BGR
            if not ret:
                st.info("è§†é¢‘æ’­æ”¾ç»“æŸ")
                break

            frame_count += 1
            if frame_count % VIDEO_FRAME_SKIP != 0:
                continue

            # === æ ¸å¿ƒå¤„ç†ï¼šä½¿ç”¨å±€éƒ¨å˜é‡ ===
            processed_frame, obj_count = process_frame(
                frame, 
                model_choice,    # âœ… å±€éƒ¨å˜é‡
                category_choice, # âœ… å±€éƒ¨å˜é‡
                conf_thres       # âœ… å±€éƒ¨å˜é‡
            )


            final_image = processed_frame
            if fix_color:
                # å‹¾é€‰æ—¶ï¼Œå°†æ£€æµ‹ç»“æœè¿”å›çš„ RGB å¼ºåˆ¶è½¬æ¢ä¸º BGR
                # ç›®çš„æ˜¯æŠµæ¶ˆ opencv æŸäº›ç‰ˆæœ¬è¯»å– BGR æ—¶æ˜¾ç¤ºçš„é¢œè‰²åè½¬
                final_image = cv2.cvtColor(processed_frame, cv2.COLOR_RGB2BGR)

            # === æ˜¾ç¤º ===
            elapsed_time = time.time() - start_time
            fps = frame_count / elapsed_time if elapsed_time > 0 else 0

            # å§‹ç»ˆå‘Šè¯‰ Streamlit å†…éƒ¨æ˜¯ RGB (å³ä½¿æˆ‘ä»¬åšäº† BGR è½¬æ¢ï¼Œæ˜¾ç¤ºæ—¶ä»æ˜¯ RGB)
            st_frame.image(final_image, channels="RGB", use_container_width=True)

            kpi_frame.metric("å·²å¤„ç†å¸§", frame_count)
            kpi_obj.metric("å½“å‰å¸§ç›®æ ‡", obj_count)
            kpi_fps.metric("FPS", f"{fps:.1f}")

        # é€€å‡ºå¾ªç¯å
        cap.release()
        st.session_state['stop_video_stream'] = False # é‡ç½®åœæ­¢æ ‡å¿—

    elif cap is not None:
         # ç¡®ä¿ cap é‡Šæ”¾
         cap.release()
         st.session_state['stop_video_stream'] = False